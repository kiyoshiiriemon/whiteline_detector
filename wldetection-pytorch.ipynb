{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_units1, n_units2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.l1 = nn.Conv2d(3, n_units1, 5, stride=1, padding=2)\n",
    "        self.l3 = nn.Conv2d(n_units1, 1, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l3(x)\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "def train(args, model, device, dataloader, optimizer, epoch):\n",
    "    model.train()\n",
    "    lossfun = nn.BCELoss()\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = lossfun(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(dataloader.dataset),\n",
    "                100. * batch_idx / len(dataloader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break\n",
    "\n",
    "class WhitelineDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        imw = 320\n",
    "        imh = 240\n",
    "        x = np.zeros((0, 3, imh, imw), dtype=np.float32)\n",
    "        t = np.zeros((0, 1, imh, imw), dtype=np.float32)\n",
    "        jpgfiles = glob.glob('*.jpg')\n",
    "        print(jpgfiles)\n",
    "        for f in jpgfiles:\n",
    "            plt.figure()\n",
    "            img = Image.open(f).resize((imw, imh))\n",
    "            plt.imshow(np.array(img))\n",
    "            a = np.asarray(img).transpose(2,0,1).astype(np.float32)/255.\n",
    "            a1 = np.expand_dims(a,axis=0)\n",
    "            x = np.append(x, a1, axis=0)\n",
    "\n",
    "            lfile = os.path.splitext(f)[0] + '_label.png'\n",
    "            print(lfile)\n",
    "            img = Image.open(lfile).resize((imw, imh))\n",
    "            img = img.convert('L')\n",
    "            timg = Image.fromarray(np.asarray(img))\n",
    "            #plt.figure()\n",
    "            #plt.imshow(timg)\n",
    "            a = np.asarray(img).astype(np.float32) > 0.01\n",
    "            a = a.astype(np.float32)\n",
    "            print(np.sum(a))\n",
    "            a1 = np.expand_dims(a,axis=0)\n",
    "            a1 = np.expand_dims(a1,axis=0)\n",
    "            t = np.append(t, a1, axis=0)\n",
    "            #timg = Image.fromarray(a * 255, 'F')\n",
    "            #plt.imshow(timg)\n",
    "        self.data  = x\n",
    "        self.label = t\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        #print(self.data.shape)\n",
    "        #print(self.label.shape)\n",
    "        images =  self.data[idx, :, :, :]\n",
    "        labels = self.label[idx, :, :]\n",
    "\n",
    "        return (images, labels)\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=14, metavar='N',\n",
    "                    help='number of epochs to train (default: 14)')\n",
    "parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n",
    "                    help='learning rate (default: 1.0)')\n",
    "parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "                    help='Learning rate step gamma (default: 0.7)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "                    help='quickly check a single pass')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--save-model', action='store_true', default=False,\n",
    "                    help='For Saving the current Model')\n",
    "args = parser.parse_args(args=[])\n",
    "dataset = WhitelineDataset('./')\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "model = MLP(4, 2).to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "for i in range(2000):\n",
    "    train(args, model=model, device=device, dataloader=train_loader, optimizer=optimizer, epoch=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device(\"cpu\")\n",
    "def eval_image(fname, thre):\n",
    "    imw = 320\n",
    "    imh = 240\n",
    "    model.to(cpu)\n",
    "    testx = np.zeros((0, 3, imh, imw), dtype=np.float32)\n",
    "\n",
    "    #y2 = (model.y.data)\n",
    "    #plt.imshow(y2[0][0])\n",
    "    img = Image.open(fname).convert('RGB').resize((imw,imh))\n",
    "    a = np.asarray(img).transpose(2,0,1).astype(np.float32)/255.\n",
    "    a1 = np.expand_dims(a,axis=0)\n",
    "    #print(a1.shape)\n",
    "    testx = np.append(testx, a1, axis=0)\n",
    "\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    testy = model(torch.FloatTensor(testx))\n",
    "    print('forward time [s]: ' + str(time.time()-t0))\n",
    "\n",
    "    #fig, axs = plt.subplots(1,3)\n",
    "    #plt.imshow(img, ax=axs[0])\n",
    "    imd = Image.new('RGB', (imw*2, imh))\n",
    "    imd.paste(img)\n",
    "    thimg = (testy.detach().to(cpu).numpy()[0][0] > thre)\n",
    "    print(thimg.shape)\n",
    "    print(f'max {np.max(thimg)}')\n",
    "    print(f'min {np.min(thimg)}')\n",
    "    thimg = thimg.astype(np.uint8) * 255\n",
    "\n",
    "    thimg = Image.fromarray(thimg)\n",
    "    plt.imshow(thimg)\n",
    "\n",
    "    imd.paste(thimg, (imw, 0))\n",
    "    plt.imshow(imd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_image('000050.png', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_image('000003.jpg', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_image('000013.jpg', 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_image('000047.jpg', 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_image('000034.jpg', .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}